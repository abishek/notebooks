{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "511c6730",
   "metadata": {},
   "source": [
    "## Classification Experiments Continued Some More\n",
    "\n",
    "In this notebook, am going to add more features for training to see if I can push the accuracy score. I want to see if I can add back Naive Bayes model as well. Finally, I'll also add F-score scoring to compare the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7443fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "251314b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'datasets/tweets.csv'\n",
    "dataframe = pd.read_csv(dataset)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2fac3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embeddings = {}\n",
    "def load_glove(glove_file):\n",
    "    with open(glove_file, 'r') as gf:\n",
    "        for line in gf:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], \"float32\")\n",
    "            glove_embeddings[word] = vector\n",
    "\n",
    "load_glove('models/glove/glove.twitter.27B.200d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "86ce6ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "mention = re.compile('^@.*')\n",
    "hashtag = re.compile('^#.*')\n",
    "punctuation = re.compile('[!#,*$%^&.\\-\\+]')\n",
    "digits = re.compile('^[0-9,\\.].*')\n",
    "urls = re.compile('^http.*')\n",
    "def cleanup(text:str) -> [str]:\n",
    "    # lowercase the text first\n",
    "    ltext = text.lower()\n",
    "    words = ltext.split(' ')\n",
    "    clean_words = []\n",
    "    # since these are tweets, remove any @ mentions. they can't really map meaningfully to lang vectors anyway.\n",
    "    for word in words:\n",
    "        # replace mentions with <user>\n",
    "        # replace hashtags with <hashtag>\n",
    "        # replace numbers with <number>\n",
    "        # replace urls with <url>\n",
    "        clean = re.sub(mention, '<user>', word)\n",
    "        clean = re.sub(hashtag, '<hashtag>', clean)\n",
    "        clean = re.sub(digits, '<number>', clean)\n",
    "        clean = re.sub(urls, '<url>', clean)\n",
    "        clean = re.sub(punctuation, '', clean)\n",
    "        if clean and clean not in stop_words:\n",
    "            clean_words.append(clean)\n",
    "    return clean_words if len(clean_words) > 0 else None\n",
    "\n",
    "\n",
    "dataframe[\"glove_clean\"] = dataframe[\"text\"].apply(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d19fc2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_vector(list_of_tokens: [str]):\n",
    "    vectors = []\n",
    "    for token in list_of_tokens:\n",
    "        vec = glove_embeddings.get(token)\n",
    "        if vec is not None:\n",
    "            vectors.append(vec)\n",
    "\n",
    "    if len(vectors) > 0:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    return None\n",
    "\n",
    "dataframe[\"glove_vectors\"] = dataframe[\"glove_clean\"].apply(glove_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "223c38ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, x_train, x_valid):\n",
    "    return {\n",
    "        \"train\": model.predict(x_train),\n",
    "        \"valid\": model.predict(x_valid),\n",
    "    }\n",
    "\n",
    "def accuracy(predictions, y_train, y_valid):\n",
    "    return {\n",
    "        \"train\": accuracy_score(y_train, predictions[\"train\"]),\n",
    "        \"valid\": accuracy_score(y_valid, predictions[\"valid\"])\n",
    "    }\n",
    "\n",
    "def compute_f1_score(predictions, y_train, y_valid):\n",
    "    return {\n",
    "        \"train\": f1_score(y_train, predictions[\"train\"], average='weighted'),\n",
    "        \"valid\": f1_score(y_valid, predictions[\"valid\"], average='weighted')\n",
    "    }\n",
    "\n",
    "def fit_and_predict_returning_metrics(model, x_train, y_train, x_valid, y_valid):\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = predict(model, x_train, x_valid)\n",
    "    acc = accuracy(predictions, y_train, y_valid)\n",
    "    #return acc\n",
    "    f1score = compute_f1_score(predictions, y_train, y_valid)\n",
    "    #return f1score\n",
    "    return model, {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1score\": f1score\n",
    "    }\n",
    "\n",
    "def logistic_regression(x_train, y_train, x_valid, y_valid):\n",
    "    lgmodel = LogisticRegression(max_iter=5000)\n",
    "    return fit_and_predict_returning_metrics(lgmodel, x_train, y_train, x_valid, y_valid)\n",
    "\n",
    "def decision_tree_classifier(x_train, y_train, x_valid, y_valid):\n",
    "    dtcmodel = DecisionTreeClassifier()\n",
    "    return fit_and_predict_returning_metrics(dtcmodel, x_train, y_train, x_valid, y_valid)\n",
    "\n",
    "def svc(x_train, y_train, x_valid, y_valid):\n",
    "    svcmodel = svm.SVC()\n",
    "    return fit_and_predict_returning_metrics(svcmodel, x_train, y_train, x_valid, y_valid)\n",
    "\n",
    "def naive_bayes(x_train, y_train, x_valid, y_valid):\n",
    "    nbmodel = MultinomialNB()\n",
    "    return fit_and_predict_returning_metrics(nbmodel, x_train, y_train, x_valid, y_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62828751",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "All of the above are the same as what we have used in the previous notebooks. So am just copy pasting them to get to the real thing fast. In the next set of cells, we will define the metadata features that we want to use as part of the training.\n",
    "\n",
    "The features we wish to capture going forward are like this:\n",
    "1. mean glove embedding vectors for the cleaned up text\n",
    "2. tfidf vectors for the cleaned up text\n",
    "3. number of mentions in the tweet\n",
    "4. number of hashtags in the tweet\n",
    "5. number of urls in the tweet\n",
    "6. length of the tweet\n",
    "7. retweet count\n",
    "8. whether the tweet is a RT or a tweet\n",
    "9. number of cleaned up tokens in the tweet\n",
    "10. count of numbers in the tweet\n",
    "\n",
    "It is possible that some of these overlap. Overlaps might negatively contribute to the overall accuracy. But let's start somewhere first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "48233bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 24)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_retweet(text: str):\n",
    "    return 1 if text.split()[0].lower() == 'RT' else 0\n",
    "\n",
    "def count_entity(ent, list_of_tokens):\n",
    "    count = 0\n",
    "    for token in list_of_tokens:\n",
    "        if token == ent:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def count_mentions(list_of_tokens):\n",
    "    return count_entity('<user>', list_of_tokens)\n",
    "\n",
    "def count_hashtags(list_of_tokens):\n",
    "    return count_entity('<hashtag>', list_of_tokens)\n",
    "\n",
    "def count_urls(list_of_tokens):\n",
    "    return count_entity('<url>', list_of_tokens)\n",
    "\n",
    "def count_numbers(list_of_tokens):\n",
    "    return count_entity('<number>', list_of_tokens)\n",
    "\n",
    "dataframe[\"num_tokens\"] =  dataframe[\"glove_clean\"].apply(lambda x: len(x))\n",
    "dataframe[\"length\"] = dataframe[\"text\"].apply(lambda x: len(x))\n",
    "dataframe[\"num_mentions\"] = dataframe[\"glove_clean\"].apply(count_mentions)\n",
    "dataframe[\"num_hashtags\"] = dataframe[\"glove_clean\"].apply(count_hashtags)\n",
    "dataframe[\"num_urls\"] = dataframe[\"glove_clean\"].apply(count_urls)\n",
    "dataframe[\"is_rt\"] = dataframe[\"text\"].apply(is_retweet)\n",
    "dataframe[\"numbers\"] = dataframe[\"glove_clean\"].apply(count_numbers)\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e5dcbda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14638, 24)\n",
      "(14638, 11321)\n"
     ]
    }
   ],
   "source": [
    "# drop all rows where the glove vectors are absent for whatever reason\n",
    "pruned_df = dataframe[dataframe[\"glove_vectors\"].notna()]\n",
    "print(pruned_df.shape)\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_vectors = tfidf.fit_transform(pruned_df[\"glove_clean\"].apply(lambda x: ' '.join((map(str, x)))))\n",
    "print(tfidf_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7982e497",
   "metadata": {},
   "source": [
    "now let's form the training set by combining all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4100793a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14638, 11529)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\"retweet_count\", \"num_tokens\", \"length\", \"num_mentions\", \"num_hashtags\", \"num_urls\", \"is_rt\", \"numbers\"]\n",
    "features_set = pruned_df[features]\n",
    "glove_set = pruned_df[\"glove_vectors\"].apply(pd.Series)\n",
    "scaler = MinMaxScaler()\n",
    "glove_set_scaled = scaler.fit_transform(glove_set)\n",
    "\n",
    "train_set = hstack([tfidf_vectors, csr_matrix(features_set), csr_matrix(glove_set_scaled )])\n",
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4155e6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14638,)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "target = le.fit_transform(pruned_df[\"airline_sentiment\"])\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "48386815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10978, 11529) (10978,)\n",
      "(3660, 11529) (3660,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(train_set, target, random_state=20, stratify=target)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "44e2de27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': {'train': 0.873656403716524, 'valid': 0.7969945355191257}, 'f1score': {'train': 0.8701546693055096, 'valid': 0.7902594262037741}}\n"
     ]
    }
   ],
   "source": [
    "lgmodel, results = logistic_regression(x_train, y_train, x_valid, y_valid)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "189b55a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': {'train': 0.9972672617963199, 'valid': 0.6418032786885246}, 'f1score': {'train': 0.9972660160562759, 'valid': 0.6431935532726364}}\n"
     ]
    }
   ],
   "source": [
    "dtcmodel, results = decision_tree_classifier(x_train, y_train, x_valid, y_valid)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c3dfa601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': {'train': 0.6386409182000364, 'valid': 0.6371584699453552}, 'f1score': {'train': 0.5349562001519731, 'valid': 0.5334870735614848}}\n"
     ]
    }
   ],
   "source": [
    "svcmodel, results = svc(x_train, y_train, x_valid, y_valid)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "359f29ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': {'train': 0.7095099289488067, 'valid': 0.6773224043715848}, 'f1score': {'train': 0.6910913881277492, 'valid': 0.652410232472699}}\n"
     ]
    }
   ],
   "source": [
    "nbmodel, results = naive_bayes(x_train, y_train, x_valid, y_valid)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e672024",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "We have an overall accuracy of around 80% with logistic regression, which performs the best in our case. Whether the metric is accuracy score or f1 score, Logic Regression simply works the best for this dataset and features. For some reason, DTC always seems to overfit. This is the only exercise I need to perform again after learning a bit of what DTC really tries to do.\n",
    "\n",
    "Going forward, I'll use F1 Score as the metric of choice. Both Andrew Ng's course and my mentor have suggested this metric. Besides, the accuracy metric is not all that far off either.\n",
    "\n",
    "Lastly, I snuck in a scaler for the glove vectors in order to be able to run a Naive Bayes classifier. I guess this set of experiments conclude here. I'll revisit classification with a different dataset in a later notebook.\n",
    "\n",
    "The next session implements a simple pipleline to take a tweet and try and predict the sentiment based on the above learning. We will use the Logistic Regression model for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0fd24512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype=object)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tweet = \"@USAirways flt 419. 2+ hrs Late Flight, baggage + 1 more hr. Now I see they delivered my suitcase wet inside &amp; out. #NotHappy\"\n",
    "\n",
    "clean_tokens = cleanup(sample_tweet)\n",
    "word_vector = scaler.transform(glove_vector(clean_tokens).reshape(1,-1))\n",
    "tfidf_vector = tfidf.transform([' '.join((map(str, clean_tokens)))])\n",
    "features = [\"retweet_count\", \"num_tokens\", \"length\", \"num_mentions\", \"num_hashtags\", \"num_urls\", \"is_rt\"]\n",
    "rtcount = 0\n",
    "num_tokens = len(clean_tokens)\n",
    "length = len(sample_tweet)\n",
    "num_mentions = 1\n",
    "num_hashtags = 1\n",
    "num_urls = 0\n",
    "is_rt = 0\n",
    "numbers = 3\n",
    "extra_features = np.array([rtcount, num_tokens, length, num_mentions, num_hashtags, num_urls, is_rt, numbers], dtype='float32')\n",
    "vector = hstack([tfidf_vector, csr_matrix(word_vector), csr_matrix(extra_features)])\n",
    "res = lgmodel.predict(vector)\n",
    "le.inverse_transform(np.array(res))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
